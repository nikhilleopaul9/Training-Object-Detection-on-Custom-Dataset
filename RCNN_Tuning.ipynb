{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RCNN_Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZjxHT-s1IcM",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4b847ca7-7436-4023-a557-d0ecf1f7a064"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-036dc06c-21be-48e4-8bae-61e9e2484eb9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-036dc06c-21be-48e4-8bae-61e9e2484eb9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving watches.zip to watches.zip\n",
            "User uploaded file \"watches.zip\" with length 54348195 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynXvqYRSXcax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "local_zip = '/content/watches.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MBWGFsvZAzp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad05b191-272d-43fd-b62a-eb73d6895f58"
      },
      "source": [
        "cd /tmp/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbuwXBcoCtvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a5c56d8a-c4ad-4ebd-9820-5864e26f10e5"
      },
      "source": [
        "!pip install ipython-autotime"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
            "Building wheels for collected packages: ipython-autotime\n",
            "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1832 sha256=1ad2ad2a846243b0736371d9cb2ccd0a2bf1147bb13f04a867c979850d3f2228\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
            "Successfully built ipython-autotime\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96comVPvDJQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autotime"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erIdcq0dVJM3",
        "colab_type": "text"
      },
      "source": [
        "**Build Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbMyr2YrU_TL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a8bdad7-0efa-459a-b089-c3e4bf19b0a5"
      },
      "source": [
        "# import the necessary packages\n",
        "import os\n",
        "\n",
        "# define the base path to the *original* input dataset and then use\n",
        "# the base path to derive the image and annotations directories\n",
        "ORIG_BASE_PATH = \"watches\"\n",
        "ORIG_IMAGES = os.path.sep.join([ORIG_BASE_PATH, \"images\"])\n",
        "ORIG_ANNOTS = os.path.sep.join([ORIG_BASE_PATH, \"annotations\"])\n",
        "\n",
        "# define the base path to the *new* dataset after running our dataset\n",
        "# builder scripts and then use the base path to derive the paths to\n",
        "# our output class label directories\n",
        "BASE_PATH = \"dataset\"\n",
        "POSITVE_PATH = os.path.sep.join([BASE_PATH, \"watch\"])\n",
        "NEGATIVE_PATH = os.path.sep.join([BASE_PATH, \"no_watch\"])\n",
        "\n",
        "# define the number of max proposals used when running selective\n",
        "# search for (1) gathering training data and (2) performing inference\n",
        "MAX_PROPOSALS = 2000\n",
        "MAX_PROPOSALS_INFER = 200\n",
        "\n",
        "# define the maximum number of positive and negative images to be\n",
        "# generated from each image\n",
        "MAX_POSITIVE = 30\n",
        "MAX_NEGATIVE = 10\n",
        "\n",
        "# initialize the input dimensions to the network\n",
        "INPUT_DIMS = (224, 224)\n",
        "\n",
        "# define the path to the output model and label binarizer\n",
        "MODEL_PATH = \"raccoon_detector.h5\"\n",
        "ENCODER_PATH = \"label_encoder.pickle\"\n",
        "\n",
        "# define the minimum probability required for a positive prediction\n",
        "# (used to filter out false-positive predictions)\n",
        "MIN_PROBA = 0.99\n",
        "\n",
        "# Intersection over Union\n",
        "def compute_iou(boxA, boxB):\n",
        "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
        "\txA = max(boxA[0], boxB[0])\n",
        "\tyA = max(boxA[1], boxB[1])\n",
        "\txB = min(boxA[2], boxB[2])\n",
        "\tyB = min(boxA[3], boxB[3])\n",
        "\n",
        "\t# compute the area of intersection rectangle\n",
        "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
        "\n",
        "\t# compute the area of both the prediction and ground-truth\n",
        "\t# rectangles\n",
        "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "\n",
        "\t# compute the intersection over union by taking the intersection\n",
        "\t# area and dividing it by the sum of prediction + ground-truth\n",
        "\t# areas - the intersection area\n",
        "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "\n",
        "\t# return the intersection over union value\n",
        "\treturn iou\n",
        "\n",
        "\n",
        "# import the necessary packages\n",
        "from bs4 import BeautifulSoup\n",
        "from imutils import paths\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# loop over the output positive and negative directories\n",
        "for dirPath in (POSITVE_PATH, NEGATIVE_PATH):\n",
        "\t# if the output directory does not exist yet, create it\n",
        "\tif not os.path.exists(dirPath):\n",
        "\t\tos.makedirs(dirPath)\n",
        "\n",
        "# grab all image paths in the input images directory\n",
        "imagePaths = list(paths.list_images(ORIG_IMAGES))\n",
        "\n",
        "# initialize the total number of positive and negative images we have\n",
        "# saved to disk so far\n",
        "totalPositive = 0\n",
        "totalNegative = 0\n",
        "\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "\t# show a progress report\n",
        "\tprint(\"[INFO] processing image {}/{}...\".format(i + 1,\n",
        "\t\tlen(imagePaths)))\n",
        "\n",
        "\t# extract the filename from the file path and use it to derive\n",
        "\t# the path to the XML annotation file\n",
        "\tfilename = imagePath.split(os.path.sep)[-1]\n",
        "\tfilename = filename[:filename.rfind(\".\")]\n",
        "\tannotPath = os.path.sep.join([ORIG_ANNOTS,\n",
        "\t\t\"{}.xml\".format(filename)])\n",
        "\n",
        "\t# load the annotation file, build the soup, and initialize our\n",
        "\t# list of ground-truth bounding boxes\n",
        "\tcontents = open(annotPath).read()\n",
        "\tsoup = BeautifulSoup(contents, \"html.parser\")\n",
        "\tgtBoxes = []\n",
        "\n",
        "\t# extract the image dimensions\n",
        "\tw = int(soup.find(\"width\").string)\n",
        "\th = int(soup.find(\"height\").string)\n",
        "\n",
        "\t# loop over all 'object' elements\n",
        "\tfor o in soup.find_all(\"object\"):\n",
        "\t\t# extract the label and bounding box coordinates\n",
        "\t\tlabel = o.find(\"name\").string\n",
        "\t\txMin = int(o.find(\"xmin\").string)\n",
        "\t\tyMin = int(o.find(\"ymin\").string)\n",
        "\t\txMax = int(o.find(\"xmax\").string)\n",
        "\t\tyMax = int(o.find(\"ymax\").string)\n",
        "\n",
        "\t\t# truncate any bounding box coordinates that may fall\n",
        "\t\t# outside the boundaries of the image\n",
        "\t\txMin = max(0, xMin)\n",
        "\t\tyMin = max(0, yMin)\n",
        "\t\txMax = min(w, xMax)\n",
        "\t\tyMax = min(h, yMax)\n",
        "\n",
        "\t\t# update our list of ground-truth bounding boxes\n",
        "\t\tgtBoxes.append((xMin, yMin, xMax, yMax))\n",
        "\n",
        "\t# load the input image from disk\n",
        "\timage = cv2.imread(imagePath)\n",
        "\n",
        "\t# run selective search on the image and initialize our list of\n",
        "\t# proposed boxes\n",
        "\tss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "\tss.setBaseImage(image)\n",
        "\tss.switchToSelectiveSearchFast()\n",
        "\trects = ss.process()\n",
        "\tproposedRects= []\n",
        "\n",
        "\t# loop over the rectangles generated by selective search\n",
        "\tfor (x, y, w, h) in rects:\n",
        "\t\t# convert our bounding boxes from (x, y, w, h) to (startX,\n",
        "\t\t# startY, startX, endY)\n",
        "\t\tproposedRects.append((x, y, x + w, y + h))\n",
        "\n",
        "\t# initialize counters used to count the number of positive and\n",
        "\t# negative ROIs saved thus far\n",
        "\tpositiveROIs = 0\n",
        "\tnegativeROIs = 0\n",
        "\n",
        "\t# loop over the maximum number of region proposals\n",
        "\tfor proposedRect in proposedRects[:MAX_PROPOSALS]:\n",
        "\t\t# unpack the proposed rectangle bounding box\n",
        "\t\t(propStartX, propStartY, propEndX, propEndY) = proposedRect\n",
        "\n",
        "\t\t# loop over the ground-truth bounding boxes\n",
        "\t\tfor gtBox in gtBoxes:\n",
        "\t\t\t# compute the intersection over union between the two\n",
        "\t\t\t# boxes and unpack the ground-truth bounding box\n",
        "\t\t\tiou = compute_iou(gtBox, proposedRect)\n",
        "\t\t\t(gtStartX, gtStartY, gtEndX, gtEndY) = gtBox\n",
        "\n",
        "\t\t\t# initialize the ROI and output path\n",
        "\t\t\troi = None\n",
        "\t\t\toutputPath = None\n",
        "\n",
        "\t\t\t# check to see if the IOU is greater than 70% *and* that\n",
        "\t\t\t# we have not hit our positive count limit\n",
        "\t\t\tif iou > 0.7 and positiveROIs <= MAX_POSITIVE:\n",
        "\t\t\t\t# extract the ROI and then derive the output path to\n",
        "\t\t\t\t# the positive instance\n",
        "\t\t\t\troi = image[propStartY:propEndY, propStartX:propEndX]\n",
        "\t\t\t\tfilename = \"{}.png\".format(totalPositive)\n",
        "\t\t\t\toutputPath = os.path.sep.join([POSITVE_PATH,\n",
        "\t\t\t\t\tfilename])\n",
        "\n",
        "\t\t\t\t# increment the positive counters\n",
        "\t\t\t\tpositiveROIs += 1\n",
        "\t\t\t\ttotalPositive += 1\n",
        "\n",
        "\t\t\t# determine if the proposed bounding box falls *within*\n",
        "\t\t\t# the ground-truth bounding box\n",
        "\t\t\tfullOverlap = propStartX >= gtStartX\n",
        "\t\t\tfullOverlap = fullOverlap and propStartY >= gtStartY\n",
        "\t\t\tfullOverlap = fullOverlap and propEndX <= gtEndX\n",
        "\t\t\tfullOverlap = fullOverlap and propEndY <= gtEndY\n",
        "\n",
        "\t\t\t# check to see if there is not full overlap *and* the IoU\n",
        "\t\t\t# is less than 5% *and* we have not hit our negative\n",
        "\t\t\t# count limit\n",
        "\t\t\tif not fullOverlap and iou < 0.05 and \\\n",
        "\t\t\t\tnegativeROIs <= MAX_NEGATIVE:\n",
        "\t\t\t\t# extract the ROI and then derive the output path to\n",
        "\t\t\t\t# the negative instance\n",
        "\t\t\t\troi = image[propStartY:propEndY, propStartX:propEndX]\n",
        "\t\t\t\tfilename = \"{}.png\".format(totalNegative)\n",
        "\t\t\t\toutputPath = os.path.sep.join([NEGATIVE_PATH,\n",
        "\t\t\t\t\tfilename])\n",
        "\n",
        "\t\t\t\t# increment the negative counters\n",
        "\t\t\t\tnegativeROIs += 1\n",
        "\t\t\t\ttotalNegative += 1\n",
        "\n",
        "\t\t\t# check to see if both the ROI and output path are valid\n",
        "\t\t\tif roi is not None and outputPath is not None:\n",
        "\t\t\t\t# resize the ROI to the input dimensions of the CNN\n",
        "\t\t\t\t# that we'll be fine-tuning, then write the ROI to\n",
        "\t\t\t\t# disk\n",
        "\t\t\t\troi = cv2.resize(roi, INPUT_DIMS,\n",
        "\t\t\t\t\tinterpolation=cv2.INTER_CUBIC)\n",
        "\t\t\t\tcv2.imwrite(outputPath, roi)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] processing image 1/423...\n",
            "[INFO] processing image 2/423...\n",
            "[INFO] processing image 3/423...\n",
            "[INFO] processing image 4/423...\n",
            "[INFO] processing image 5/423...\n",
            "[INFO] processing image 6/423...\n",
            "[INFO] processing image 7/423...\n",
            "[INFO] processing image 8/423...\n",
            "[INFO] processing image 9/423...\n",
            "[INFO] processing image 10/423...\n",
            "[INFO] processing image 11/423...\n",
            "[INFO] processing image 12/423...\n",
            "[INFO] processing image 13/423...\n",
            "[INFO] processing image 14/423...\n",
            "[INFO] processing image 15/423...\n",
            "[INFO] processing image 16/423...\n",
            "[INFO] processing image 17/423...\n",
            "[INFO] processing image 18/423...\n",
            "[INFO] processing image 19/423...\n",
            "[INFO] processing image 20/423...\n",
            "[INFO] processing image 21/423...\n",
            "[INFO] processing image 22/423...\n",
            "[INFO] processing image 23/423...\n",
            "[INFO] processing image 24/423...\n",
            "[INFO] processing image 25/423...\n",
            "[INFO] processing image 26/423...\n",
            "[INFO] processing image 27/423...\n",
            "[INFO] processing image 28/423...\n",
            "[INFO] processing image 29/423...\n",
            "[INFO] processing image 30/423...\n",
            "[INFO] processing image 31/423...\n",
            "[INFO] processing image 32/423...\n",
            "[INFO] processing image 33/423...\n",
            "[INFO] processing image 34/423...\n",
            "[INFO] processing image 35/423...\n",
            "[INFO] processing image 36/423...\n",
            "[INFO] processing image 37/423...\n",
            "[INFO] processing image 38/423...\n",
            "[INFO] processing image 39/423...\n",
            "[INFO] processing image 40/423...\n",
            "[INFO] processing image 41/423...\n",
            "[INFO] processing image 42/423...\n",
            "[INFO] processing image 43/423...\n",
            "[INFO] processing image 44/423...\n",
            "[INFO] processing image 45/423...\n",
            "[INFO] processing image 46/423...\n",
            "[INFO] processing image 47/423...\n",
            "[INFO] processing image 48/423...\n",
            "[INFO] processing image 49/423...\n",
            "[INFO] processing image 50/423...\n",
            "[INFO] processing image 51/423...\n",
            "[INFO] processing image 52/423...\n",
            "[INFO] processing image 53/423...\n",
            "[INFO] processing image 54/423...\n",
            "[INFO] processing image 55/423...\n",
            "[INFO] processing image 56/423...\n",
            "[INFO] processing image 57/423...\n",
            "[INFO] processing image 58/423...\n",
            "[INFO] processing image 59/423...\n",
            "[INFO] processing image 60/423...\n",
            "[INFO] processing image 61/423...\n",
            "[INFO] processing image 62/423...\n",
            "[INFO] processing image 63/423...\n",
            "[INFO] processing image 64/423...\n",
            "[INFO] processing image 65/423...\n",
            "[INFO] processing image 66/423...\n",
            "[INFO] processing image 67/423...\n",
            "[INFO] processing image 68/423...\n",
            "[INFO] processing image 69/423...\n",
            "[INFO] processing image 70/423...\n",
            "[INFO] processing image 71/423...\n",
            "[INFO] processing image 72/423...\n",
            "[INFO] processing image 73/423...\n",
            "[INFO] processing image 74/423...\n",
            "[INFO] processing image 75/423...\n",
            "[INFO] processing image 76/423...\n",
            "[INFO] processing image 77/423...\n",
            "[INFO] processing image 78/423...\n",
            "[INFO] processing image 79/423...\n",
            "[INFO] processing image 80/423...\n",
            "[INFO] processing image 81/423...\n",
            "[INFO] processing image 82/423...\n",
            "[INFO] processing image 83/423...\n",
            "[INFO] processing image 84/423...\n",
            "[INFO] processing image 85/423...\n",
            "[INFO] processing image 86/423...\n",
            "[INFO] processing image 87/423...\n",
            "[INFO] processing image 88/423...\n",
            "[INFO] processing image 89/423...\n",
            "[INFO] processing image 90/423...\n",
            "[INFO] processing image 91/423...\n",
            "[INFO] processing image 92/423...\n",
            "[INFO] processing image 93/423...\n",
            "[INFO] processing image 94/423...\n",
            "[INFO] processing image 95/423...\n",
            "[INFO] processing image 96/423...\n",
            "[INFO] processing image 97/423...\n",
            "[INFO] processing image 98/423...\n",
            "[INFO] processing image 99/423...\n",
            "[INFO] processing image 100/423...\n",
            "[INFO] processing image 101/423...\n",
            "[INFO] processing image 102/423...\n",
            "[INFO] processing image 103/423...\n",
            "[INFO] processing image 104/423...\n",
            "[INFO] processing image 105/423...\n",
            "[INFO] processing image 106/423...\n",
            "[INFO] processing image 107/423...\n",
            "[INFO] processing image 108/423...\n",
            "[INFO] processing image 109/423...\n",
            "[INFO] processing image 110/423...\n",
            "[INFO] processing image 111/423...\n",
            "[INFO] processing image 112/423...\n",
            "[INFO] processing image 113/423...\n",
            "[INFO] processing image 114/423...\n",
            "[INFO] processing image 115/423...\n",
            "[INFO] processing image 116/423...\n",
            "[INFO] processing image 117/423...\n",
            "[INFO] processing image 118/423...\n",
            "[INFO] processing image 119/423...\n",
            "[INFO] processing image 120/423...\n",
            "[INFO] processing image 121/423...\n",
            "[INFO] processing image 122/423...\n",
            "[INFO] processing image 123/423...\n",
            "[INFO] processing image 124/423...\n",
            "[INFO] processing image 125/423...\n",
            "[INFO] processing image 126/423...\n",
            "[INFO] processing image 127/423...\n",
            "[INFO] processing image 128/423...\n",
            "[INFO] processing image 129/423...\n",
            "[INFO] processing image 130/423...\n",
            "[INFO] processing image 131/423...\n",
            "[INFO] processing image 132/423...\n",
            "[INFO] processing image 133/423...\n",
            "[INFO] processing image 134/423...\n",
            "[INFO] processing image 135/423...\n",
            "[INFO] processing image 136/423...\n",
            "[INFO] processing image 137/423...\n",
            "[INFO] processing image 138/423...\n",
            "[INFO] processing image 139/423...\n",
            "[INFO] processing image 140/423...\n",
            "[INFO] processing image 141/423...\n",
            "[INFO] processing image 142/423...\n",
            "[INFO] processing image 143/423...\n",
            "[INFO] processing image 144/423...\n",
            "[INFO] processing image 145/423...\n",
            "[INFO] processing image 146/423...\n",
            "[INFO] processing image 147/423...\n",
            "[INFO] processing image 148/423...\n",
            "[INFO] processing image 149/423...\n",
            "[INFO] processing image 150/423...\n",
            "[INFO] processing image 151/423...\n",
            "[INFO] processing image 152/423...\n",
            "[INFO] processing image 153/423...\n",
            "[INFO] processing image 154/423...\n",
            "[INFO] processing image 155/423...\n",
            "[INFO] processing image 156/423...\n",
            "[INFO] processing image 157/423...\n",
            "[INFO] processing image 158/423...\n",
            "[INFO] processing image 159/423...\n",
            "[INFO] processing image 160/423...\n",
            "[INFO] processing image 161/423...\n",
            "[INFO] processing image 162/423...\n",
            "[INFO] processing image 163/423...\n",
            "[INFO] processing image 164/423...\n",
            "[INFO] processing image 165/423...\n",
            "[INFO] processing image 166/423...\n",
            "[INFO] processing image 167/423...\n",
            "[INFO] processing image 168/423...\n",
            "[INFO] processing image 169/423...\n",
            "[INFO] processing image 170/423...\n",
            "[INFO] processing image 171/423...\n",
            "[INFO] processing image 172/423...\n",
            "[INFO] processing image 173/423...\n",
            "[INFO] processing image 174/423...\n",
            "[INFO] processing image 175/423...\n",
            "[INFO] processing image 176/423...\n",
            "[INFO] processing image 177/423...\n",
            "[INFO] processing image 178/423...\n",
            "[INFO] processing image 179/423...\n",
            "[INFO] processing image 180/423...\n",
            "[INFO] processing image 181/423...\n",
            "[INFO] processing image 182/423...\n",
            "[INFO] processing image 183/423...\n",
            "[INFO] processing image 184/423...\n",
            "[INFO] processing image 185/423...\n",
            "[INFO] processing image 186/423...\n",
            "[INFO] processing image 187/423...\n",
            "[INFO] processing image 188/423...\n",
            "[INFO] processing image 189/423...\n",
            "[INFO] processing image 190/423...\n",
            "[INFO] processing image 191/423...\n",
            "[INFO] processing image 192/423...\n",
            "[INFO] processing image 193/423...\n",
            "[INFO] processing image 194/423...\n",
            "[INFO] processing image 195/423...\n",
            "[INFO] processing image 196/423...\n",
            "[INFO] processing image 197/423...\n",
            "[INFO] processing image 198/423...\n",
            "[INFO] processing image 199/423...\n",
            "[INFO] processing image 200/423...\n",
            "[INFO] processing image 201/423...\n",
            "[INFO] processing image 202/423...\n",
            "[INFO] processing image 203/423...\n",
            "[INFO] processing image 204/423...\n",
            "[INFO] processing image 205/423...\n",
            "[INFO] processing image 206/423...\n",
            "[INFO] processing image 207/423...\n",
            "[INFO] processing image 208/423...\n",
            "[INFO] processing image 209/423...\n",
            "[INFO] processing image 210/423...\n",
            "[INFO] processing image 211/423...\n",
            "[INFO] processing image 212/423...\n",
            "[INFO] processing image 213/423...\n",
            "[INFO] processing image 214/423...\n",
            "[INFO] processing image 215/423...\n",
            "[INFO] processing image 216/423...\n",
            "[INFO] processing image 217/423...\n",
            "[INFO] processing image 218/423...\n",
            "[INFO] processing image 219/423...\n",
            "[INFO] processing image 220/423...\n",
            "[INFO] processing image 221/423...\n",
            "[INFO] processing image 222/423...\n",
            "[INFO] processing image 223/423...\n",
            "[INFO] processing image 224/423...\n",
            "[INFO] processing image 225/423...\n",
            "[INFO] processing image 226/423...\n",
            "[INFO] processing image 227/423...\n",
            "[INFO] processing image 228/423...\n",
            "[INFO] processing image 229/423...\n",
            "[INFO] processing image 230/423...\n",
            "[INFO] processing image 231/423...\n",
            "[INFO] processing image 232/423...\n",
            "[INFO] processing image 233/423...\n",
            "[INFO] processing image 234/423...\n",
            "[INFO] processing image 235/423...\n",
            "[INFO] processing image 236/423...\n",
            "[INFO] processing image 237/423...\n",
            "[INFO] processing image 238/423...\n",
            "[INFO] processing image 239/423...\n",
            "[INFO] processing image 240/423...\n",
            "[INFO] processing image 241/423...\n",
            "[INFO] processing image 242/423...\n",
            "[INFO] processing image 243/423...\n",
            "[INFO] processing image 244/423...\n",
            "[INFO] processing image 245/423...\n",
            "[INFO] processing image 246/423...\n",
            "[INFO] processing image 247/423...\n",
            "[INFO] processing image 248/423...\n",
            "[INFO] processing image 249/423...\n",
            "[INFO] processing image 250/423...\n",
            "[INFO] processing image 251/423...\n",
            "[INFO] processing image 252/423...\n",
            "[INFO] processing image 253/423...\n",
            "[INFO] processing image 254/423...\n",
            "[INFO] processing image 255/423...\n",
            "[INFO] processing image 256/423...\n",
            "[INFO] processing image 257/423...\n",
            "[INFO] processing image 258/423...\n",
            "[INFO] processing image 259/423...\n",
            "[INFO] processing image 260/423...\n",
            "[INFO] processing image 261/423...\n",
            "[INFO] processing image 262/423...\n",
            "[INFO] processing image 263/423...\n",
            "[INFO] processing image 264/423...\n",
            "[INFO] processing image 265/423...\n",
            "[INFO] processing image 266/423...\n",
            "[INFO] processing image 267/423...\n",
            "[INFO] processing image 268/423...\n",
            "[INFO] processing image 269/423...\n",
            "[INFO] processing image 270/423...\n",
            "[INFO] processing image 271/423...\n",
            "[INFO] processing image 272/423...\n",
            "[INFO] processing image 273/423...\n",
            "[INFO] processing image 274/423...\n",
            "[INFO] processing image 275/423...\n",
            "[INFO] processing image 276/423...\n",
            "[INFO] processing image 277/423...\n",
            "[INFO] processing image 278/423...\n",
            "[INFO] processing image 279/423...\n",
            "[INFO] processing image 280/423...\n",
            "[INFO] processing image 281/423...\n",
            "[INFO] processing image 282/423...\n",
            "[INFO] processing image 283/423...\n",
            "[INFO] processing image 284/423...\n",
            "[INFO] processing image 285/423...\n",
            "[INFO] processing image 286/423...\n",
            "[INFO] processing image 287/423...\n",
            "[INFO] processing image 288/423...\n",
            "[INFO] processing image 289/423...\n",
            "[INFO] processing image 290/423...\n",
            "[INFO] processing image 291/423...\n",
            "[INFO] processing image 292/423...\n",
            "[INFO] processing image 293/423...\n",
            "[INFO] processing image 294/423...\n",
            "[INFO] processing image 295/423...\n",
            "[INFO] processing image 296/423...\n",
            "[INFO] processing image 297/423...\n",
            "[INFO] processing image 298/423...\n",
            "[INFO] processing image 299/423...\n",
            "[INFO] processing image 300/423...\n",
            "[INFO] processing image 301/423...\n",
            "[INFO] processing image 302/423...\n",
            "[INFO] processing image 303/423...\n",
            "[INFO] processing image 304/423...\n",
            "[INFO] processing image 305/423...\n",
            "[INFO] processing image 306/423...\n",
            "[INFO] processing image 307/423...\n",
            "[INFO] processing image 308/423...\n",
            "[INFO] processing image 309/423...\n",
            "[INFO] processing image 310/423...\n",
            "[INFO] processing image 311/423...\n",
            "[INFO] processing image 312/423...\n",
            "[INFO] processing image 313/423...\n",
            "[INFO] processing image 314/423...\n",
            "[INFO] processing image 315/423...\n",
            "[INFO] processing image 316/423...\n",
            "[INFO] processing image 317/423...\n",
            "[INFO] processing image 318/423...\n",
            "[INFO] processing image 319/423...\n",
            "[INFO] processing image 320/423...\n",
            "[INFO] processing image 321/423...\n",
            "[INFO] processing image 322/423...\n",
            "[INFO] processing image 323/423...\n",
            "[INFO] processing image 324/423...\n",
            "[INFO] processing image 325/423...\n",
            "[INFO] processing image 326/423...\n",
            "[INFO] processing image 327/423...\n",
            "[INFO] processing image 328/423...\n",
            "[INFO] processing image 329/423...\n",
            "[INFO] processing image 330/423...\n",
            "[INFO] processing image 331/423...\n",
            "[INFO] processing image 332/423...\n",
            "[INFO] processing image 333/423...\n",
            "[INFO] processing image 334/423...\n",
            "[INFO] processing image 335/423...\n",
            "[INFO] processing image 336/423...\n",
            "[INFO] processing image 337/423...\n",
            "[INFO] processing image 338/423...\n",
            "[INFO] processing image 339/423...\n",
            "[INFO] processing image 340/423...\n",
            "[INFO] processing image 341/423...\n",
            "[INFO] processing image 342/423...\n",
            "[INFO] processing image 343/423...\n",
            "[INFO] processing image 344/423...\n",
            "[INFO] processing image 345/423...\n",
            "[INFO] processing image 346/423...\n",
            "[INFO] processing image 347/423...\n",
            "[INFO] processing image 348/423...\n",
            "[INFO] processing image 349/423...\n",
            "[INFO] processing image 350/423...\n",
            "[INFO] processing image 351/423...\n",
            "[INFO] processing image 352/423...\n",
            "[INFO] processing image 353/423...\n",
            "[INFO] processing image 354/423...\n",
            "[INFO] processing image 355/423...\n",
            "[INFO] processing image 356/423...\n",
            "[INFO] processing image 357/423...\n",
            "[INFO] processing image 358/423...\n",
            "[INFO] processing image 359/423...\n",
            "[INFO] processing image 360/423...\n",
            "[INFO] processing image 361/423...\n",
            "[INFO] processing image 362/423...\n",
            "[INFO] processing image 363/423...\n",
            "[INFO] processing image 364/423...\n",
            "[INFO] processing image 365/423...\n",
            "[INFO] processing image 366/423...\n",
            "[INFO] processing image 367/423...\n",
            "[INFO] processing image 368/423...\n",
            "[INFO] processing image 369/423...\n",
            "[INFO] processing image 370/423...\n",
            "[INFO] processing image 371/423...\n",
            "[INFO] processing image 372/423...\n",
            "[INFO] processing image 373/423...\n",
            "[INFO] processing image 374/423...\n",
            "[INFO] processing image 375/423...\n",
            "[INFO] processing image 376/423...\n",
            "[INFO] processing image 377/423...\n",
            "[INFO] processing image 378/423...\n",
            "[INFO] processing image 379/423...\n",
            "[INFO] processing image 380/423...\n",
            "[INFO] processing image 381/423...\n",
            "[INFO] processing image 382/423...\n",
            "[INFO] processing image 383/423...\n",
            "[INFO] processing image 384/423...\n",
            "[INFO] processing image 385/423...\n",
            "[INFO] processing image 386/423...\n",
            "[INFO] processing image 387/423...\n",
            "[INFO] processing image 388/423...\n",
            "[INFO] processing image 389/423...\n",
            "[INFO] processing image 390/423...\n",
            "[INFO] processing image 391/423...\n",
            "[INFO] processing image 392/423...\n",
            "[INFO] processing image 393/423...\n",
            "[INFO] processing image 394/423...\n",
            "[INFO] processing image 395/423...\n",
            "[INFO] processing image 396/423...\n",
            "[INFO] processing image 397/423...\n",
            "[INFO] processing image 398/423...\n",
            "[INFO] processing image 399/423...\n",
            "[INFO] processing image 400/423...\n",
            "[INFO] processing image 401/423...\n",
            "[INFO] processing image 402/423...\n",
            "[INFO] processing image 403/423...\n",
            "[INFO] processing image 404/423...\n",
            "[INFO] processing image 405/423...\n",
            "[INFO] processing image 406/423...\n",
            "[INFO] processing image 407/423...\n",
            "[INFO] processing image 408/423...\n",
            "[INFO] processing image 409/423...\n",
            "[INFO] processing image 410/423...\n",
            "[INFO] processing image 411/423...\n",
            "[INFO] processing image 412/423...\n",
            "[INFO] processing image 413/423...\n",
            "[INFO] processing image 414/423...\n",
            "[INFO] processing image 415/423...\n",
            "[INFO] processing image 416/423...\n",
            "[INFO] processing image 417/423...\n",
            "[INFO] processing image 418/423...\n",
            "[INFO] processing image 419/423...\n",
            "[INFO] processing image 420/423...\n",
            "[INFO] processing image 421/423...\n",
            "[INFO] processing image 422/423...\n",
            "[INFO] processing image 423/423...\n",
            "time: 2h 38min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQgw_KEyeAjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "be8ee4bd-8be6-44e4-b704-e11b532aaa4a"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "from keras.applications import resnet50\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.15 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaomfnpUPJsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e853a5b7-53a6-486d-86d6-918cc43d48ff"
      },
      "source": [
        "# define the base path to the *original* input dataset and then use\n",
        "# the base path to derive the image and annotations directories\n",
        "ORIG_BASE_PATH = \"watches\"\n",
        "ORIG_IMAGES = os.path.sep.join([ORIG_BASE_PATH, \"images\"])\n",
        "ORIG_ANNOTS = os.path.sep.join([ORIG_BASE_PATH, \"annotations\"])\n",
        "\n",
        "# define the base path to the *new* dataset after running our dataset\n",
        "# builder scripts and then use the base path to derive the paths to\n",
        "# our output class label directories\n",
        "BASE_PATH = \"dataset\"\n",
        "POSITVE_PATH = os.path.sep.join([BASE_PATH, \"watch\"])\n",
        "NEGATIVE_PATH = os.path.sep.join([BASE_PATH, \"no_watch\"])\n",
        "\n",
        "# define the number of max proposals used when running selective\n",
        "# search for (1) gathering training data and (2) performing inference\n",
        "MAX_PROPOSALS = 2000\n",
        "MAX_PROPOSALS_INFER = 200\n",
        "\n",
        "# define the maximum number of positive and negative images to be\n",
        "# generated from each image\n",
        "MAX_POSITIVE = 30\n",
        "MAX_NEGATIVE = 10\n",
        "\n",
        "# initialize the input dimensions to the network\n",
        "INPUT_DIMS = (224, 224)\n",
        "\n",
        "# define the path to the output model and label binarizer\n",
        "MODEL_PATH = \"watch_detector.h5\"\n",
        "ENCODER_PATH = \"label_encoder.pickle\"\n",
        "\n",
        "# define the minimum probability required for a positive prediction\n",
        "# (used to filter out false-positive predictions)\n",
        "MIN_PROBA = 0.99"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 11 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pgr2EpqPUDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8cbdbed5-5b6e-4f0a-87dc-39a328f1d0eb"
      },
      "source": [
        "# initialize the initial learning rate, number of epochs to train for,\n",
        "# and batch size\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 5\n",
        "BS = 32\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class labels\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(BASE_PATH))\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the input image (224x224) and preprocess it\n",
        "\timage = load_img(imagePath, target_size=INPUT_DIMS)\n",
        "\timage = img_to_array(image)\n",
        "\timage = preprocess_input(image)\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "time: 18.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJy9C8GxPdhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd9d751a-158e-4c74-8870-f4490fbf0776"
      },
      "source": [
        "# convert the data and labels to NumPy arrays\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.20, stratify=labels, random_state=42)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTZ8TY2LPxsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0927cca7-1d19-4e7e-d641-92f9e47a8cc5"
      },
      "source": [
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 5.72 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsQ6mhFPQOHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0d8fbdbe-eee7-4832-e8fd-0bf1a40de06c"
      },
      "source": [
        "# load the ResNEt50 network, ensuring the head FC layer sets are\n",
        "# left off\n",
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "time: 4.54 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAygKiBDQepx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "a2766f4f-82bb-4cb6-8452-035792b6ce26"
      },
      "source": [
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# compile our model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "[INFO] training head...\n",
            "Epoch 1/5\n",
            "210/210 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.8783WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 52 batches). You may need to use the repeat() function when building your dataset.\n",
            "210/210 [==============================] - 1259s 6s/step - loss: 0.2984 - accuracy: 0.8783 - val_loss: 0.1545 - val_accuracy: 0.9417\n",
            "Epoch 2/5\n",
            "210/210 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.9302WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 52 batches). You may need to use the repeat() function when building your dataset.\n",
            "210/210 [==============================] - 1265s 6s/step - loss: 0.1834 - accuracy: 0.9302 - val_loss: 0.1274 - val_accuracy: 0.9518\n",
            "Epoch 3/5\n",
            "210/210 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9443WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 52 batches). You may need to use the repeat() function when building your dataset.\n",
            "210/210 [==============================] - 1287s 6s/step - loss: 0.1605 - accuracy: 0.9443 - val_loss: 0.1165 - val_accuracy: 0.9542\n",
            "Epoch 4/5\n",
            "210/210 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9478WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 52 batches). You may need to use the repeat() function when building your dataset.\n",
            "210/210 [==============================] - 1287s 6s/step - loss: 0.1469 - accuracy: 0.9478 - val_loss: 0.1193 - val_accuracy: 0.9619\n",
            "Epoch 5/5\n",
            "210/210 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9512WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 52 batches). You may need to use the repeat() function when building your dataset.\n",
            "210/210 [==============================] - 1299s 6s/step - loss: 0.1363 - accuracy: 0.9512 - val_loss: 0.1314 - val_accuracy: 0.9595\n",
            "time: 1h 47min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNhdxY8_Qsry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dd0e5f42-f475-46cf-b74d-7082dae4be94"
      },
      "source": [
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    no_watch       0.99      0.94      0.96       928\n",
            "       watch       0.93      0.99      0.96       752\n",
            "\n",
            "    accuracy                           0.96      1680\n",
            "   macro avg       0.96      0.96      0.96      1680\n",
            "weighted avg       0.96      0.96      0.96      1680\n",
            "\n",
            "time: 4min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3b7KwZJutZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bae9200b-b2da-461b-9a38-f9ac1b2a0465"
      },
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "model.save(MODEL_PATH, save_format=\"h5\")\n",
        "\n",
        "# serialize the label encoder to disk\n",
        "print(\"[INFO] saving label encoder...\")\n",
        "f = open(ENCODER_PATH, \"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] saving mask detector model...\n",
            "[INFO] saving label encoder...\n",
            "time: 762 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYGo0ij5mmQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}